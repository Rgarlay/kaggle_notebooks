{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b4e327",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:19.379233Z",
     "iopub.status.busy": "2025-08-11T10:07:19.378390Z",
     "iopub.status.idle": "2025-08-11T10:07:24.425889Z",
     "shell.execute_reply": "2025-08-11T10:07:24.424629Z"
    },
    "papermill": {
     "duration": 5.055479,
     "end_time": "2025-08-11T10:07:24.427771",
     "exception": false,
     "start_time": "2025-08-11T10:07:19.372292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n",
      "/kaggle/input/jigsaw-agile-community-rules/train.csv\n",
      "/kaggle/input/jigsaw-agile-community-rules/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353bdaee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.441487Z",
     "iopub.status.busy": "2025-08-11T10:07:24.440364Z",
     "iopub.status.idle": "2025-08-11T10:07:24.455879Z",
     "shell.execute_reply": "2025-08-11T10:07:24.455029Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.023997,
     "end_time": "2025-08-11T10:07:24.457322",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.433325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_stopwords = {\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'a', 'about', 'above', 'across', 'after', 'afterwards',\n",
    "                      'again', 'against', 'ain', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always',\n",
    "                      'am', 'among', 'amongst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', \n",
    "                      'anywhere', 'are', 'aren', \"aren't\", 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes',\n",
    "                      'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', \n",
    "                      'both', 'bottom', 'but', 'by', 'ca', 'call', 'can', 'cannot', 'could', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\",\n",
    "                      'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'done', 'down', 'due', 'during', 'each', 'eight', 'either', \n",
    "                      'eleven', 'else', 'elsewhere', 'empty', 'enough', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except',\n",
    "                      'few', 'fifteen', 'fifty', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'four', 'from', 'front', 'full', 'further',\n",
    "                      'get', 'give', 'go', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \n",
    "                      \"he'll\", \"he's\", 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself',\n",
    "                      'his', 'how', 'however', 'hundred', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'indeed', 'into', 'is', 'isn', \"isn't\",\n",
    "                      'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'll', 'm', \n",
    "                      'ma', 'made', 'make', 'many', 'may', 'me', 'meanwhile', 'might', 'mightn', \"mightn't\", 'mine', 'more', 'moreover', 'most',\n",
    "                      'mostly', 'move', 'much', 'must', 'mustn', \"mustn't\", 'my', 'myself', \"n't\", 'name', 'namely', 'needn', \"needn't\", 'neither', \n",
    "                      'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'n‘t',\n",
    "                      'n’t', 'o', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours',\n",
    "                      'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'quite', 'rather', 're', 'really', 'regarding',\n",
    "                      's', 'same', 'say', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'shan', \"shan't\", 'she', \"she'd\",\n",
    "                      \"she'll\", \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'show', 'side', 'since', 'six', 'sixty', 'so', 'some',\n",
    "                      'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 't', 'take', 'ten', 'than', \n",
    "                      'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', \n",
    "                      'therefore', 'therein', 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'third', 'this', 'those', \n",
    "                      'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve',\n",
    "                      'twenty', 'two', 'under', 'unless', 'until', 'up', 'upon', 'us', 'used', 'using', 'various', 've', 'very', 'via', 'was', \n",
    "                      'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'well', 'were', 'weren', \"weren't\", 'what', 'whatever', 'when',\n",
    "                      'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which',\n",
    "                      'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'won', \"won't\",\n",
    "                      'would', 'wouldn', \"wouldn't\", 'y', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself',\n",
    "                      'yourselves', '‘d', '‘ll', '‘m', '‘re', '‘s', '‘ve', '’d', '’ll', '’m', '’re', '’s', '’ve'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cfc06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.466950Z",
     "iopub.status.busy": "2025-08-11T10:07:24.466593Z",
     "iopub.status.idle": "2025-08-11T10:07:24.558897Z",
     "shell.execute_reply": "2025-08-11T10:07:24.557942Z"
    },
    "papermill": {
     "duration": 0.099059,
     "end_time": "2025-08-11T10:07:24.560804",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.461745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_original = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/train.csv')\n",
    "df_test_original = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab60dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.570475Z",
     "iopub.status.busy": "2025-08-11T10:07:24.570161Z",
     "iopub.status.idle": "2025-08-11T10:07:24.574714Z",
     "shell.execute_reply": "2025-08-11T10:07:24.573593Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.011206,
     "end_time": "2025-08-11T10:07:24.576236",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.565030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def dataset_basics(df):\n",
    "#     print(f'Number of empty rows \\n {df_train.isna().sum()} \\n')\n",
    "#     print(f'Number of duplicate rows {df.duplicated().sum()} \\n')\n",
    "#     print(f'\\n Dtypes and other info \\n {df.info()} \\n')\n",
    "#     print(f'Shape of the dataframe {df.shape}')\n",
    "#     print(f'no_of unique subreddits',df['subreddit'].nunique())\n",
    "#     print(f'Percent of 0s and 1s: ',df['rule_violation'].value_counts()/df_train.shape[0] * 100)\n",
    "# dataset_basics(df_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e5145a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.585563Z",
     "iopub.status.busy": "2025-08-11T10:07:24.585223Z",
     "iopub.status.idle": "2025-08-11T10:07:24.635535Z",
     "shell.execute_reply": "2025-08-11T10:07:24.634585Z"
    },
    "papermill": {
     "duration": 0.05705,
     "end_time": "2025-08-11T10:07:24.637455",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.580405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train_original['rule'].str.split(',',expand=True)\n",
    "\n",
    "df_train.fillna('0',inplace=True)\n",
    "\n",
    "df_train.columns = ['rule 1','rule 2','rule 3','rule 4']\n",
    "\n",
    "## till here it works perfectly\n",
    "\n",
    "df_train['rule 2'] = df_train['rule 2'].apply(lambda x : 1 if 'referral links' in str(x).lower() else 0)\n",
    "\n",
    "df_train = df_train.rename(columns = {'rule 2':'referral link allowed'})\n",
    "\n",
    "#column 0 (legal_advice)\n",
    "\n",
    "df_train['legal_advice_allowed'] = df_train['rule 1'].apply(lambda x: 0 if 'legal' in str(x).lower() else 1)\n",
    "\n",
    "#column 1\n",
    "df_train['rule 4'] = df_train['rule 4'].apply(lambda x: 0 if 'promotional' in str(x).lower() else 1)\n",
    "\n",
    "df_train = df_train.rename(columns = {'rule 4':'Promotions allowed'})\n",
    "\n",
    "##column 1: advertising\n",
    "\n",
    "df_train['rule 3'] = df_train['rule 3'].apply(lambda x: 0 if 'advertising' in str(x).lower() else 1)\n",
    "\n",
    "df_train = df_train.rename(columns = {'rule 3':'Advertising allowed'})\n",
    "\n",
    "## Dealing with  spam part using new created dataframe\n",
    "\n",
    "df_train_1 = df_train['rule 1'].str.split(':',expand=True)\n",
    "\n",
    "df_train = df_train.drop(columns = ['rule 1'])\n",
    "\n",
    "df_train_1.columns = ['Advert','spam']\n",
    "\n",
    "df_train_1 = df_train_1.drop(columns = ['Advert'])\n",
    "    \n",
    "df_train_1['spam allowed'] = df_train_1['spam'].apply(lambda x: 0 if 'spam' in str(x).lower() else 1)\n",
    "\n",
    "df_train['spam allowed'] = df_train_1['spam allowed']\n",
    "\n",
    "### Testing Data \n",
    "\n",
    "df_test = df_test_original['rule'].str.split(',', expand=True)\n",
    "\n",
    "df_test.fillna('0', inplace=True)\n",
    "\n",
    "df_test.columns = ['rule 1', 'rule 2', 'rule 3', 'rule 4']\n",
    "\n",
    "## till here it works perfectly\n",
    "\n",
    "df_test['rule 2'] = df_test['rule 2'].apply(lambda x: 1 if 'referral links' in str(x).lower() else 0)\n",
    "\n",
    "df_test = df_test.rename(columns={'rule 2': 'referral link allowed'})\n",
    "\n",
    "# column 0 (legal_advice)\n",
    "df_test['legal_advice_allowed'] = df_test['rule 1'].apply(lambda x: 0 if 'legal' in str(x).lower() else 1)\n",
    "\n",
    "# column 1\n",
    "df_test['rule 4'] = df_test['rule 4'].apply(lambda x: 0 if 'promotional' in str(x).lower() else 1)\n",
    "\n",
    "df_test = df_test.rename(columns={'rule 4': 'Promotions allowed'})\n",
    "\n",
    "# column 1: advertising\n",
    "df_test['rule 3'] = df_test['rule 3'].apply(lambda x: 0 if 'advertising' in str(x).lower() else 1)\n",
    "\n",
    "df_test = df_test.rename(columns={'rule 3': 'Advertising allowed'})\n",
    "\n",
    "## Dealing with spam part using new created dataframe\n",
    "df_test_1 = df_test['rule 1'].str.split(':', expand=True)\n",
    "\n",
    "df_test = df_test.drop(columns=['rule 1'])\n",
    "\n",
    "df_test_1.columns = ['Advert', 'spam']\n",
    "\n",
    "df_test_1 = df_test_1.drop(columns=['Advert'])\n",
    "    \n",
    "df_test_1['spam allowed'] = df_test_1['spam'].apply(lambda x: 0 if 'spam' in str(x).lower() else 1)\n",
    "\n",
    "df_test['spam allowed'] = df_test_1['spam allowed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03c77e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.647239Z",
     "iopub.status.busy": "2025-08-11T10:07:24.646867Z",
     "iopub.status.idle": "2025-08-11T10:07:24.656192Z",
     "shell.execute_reply": "2025-08-11T10:07:24.655304Z"
    },
    "papermill": {
     "duration": 0.016159,
     "end_time": "2025-08-11T10:07:24.657905",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.641746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in df_train.columns:\n",
    "    df_train_original[i] = df_train[i]\n",
    "\n",
    "for i in df_test.columns:\n",
    "    df_test_original[i] = df_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6de223b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.668021Z",
     "iopub.status.busy": "2025-08-11T10:07:24.667708Z",
     "iopub.status.idle": "2025-08-11T10:07:24.688777Z",
     "shell.execute_reply": "2025-08-11T10:07:24.687762Z"
    },
    "papermill": {
     "duration": 0.028382,
     "end_time": "2025-08-11T10:07:24.690467",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.662085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_original = df_train_original[['body', 'rule_violation','referral link allowed', 'Advertising allowed',\n",
    "           'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n",
    "    \n",
    "df_p1 = df_train_original[['positive_example_1','rule_violation','referral link allowed', 'Advertising allowed',\n",
    "               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n",
    "\n",
    "df_p1.loc[:,'rule_violation'] = 0\n",
    "df_p1 = df_p1.rename(columns = {'positive_example_1':'body'})\n",
    "        \n",
    "df_p2 = df_train_original[['positive_example_2','rule_violation','referral link allowed', 'Advertising allowed',\n",
    "               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n",
    "\n",
    "df_p2.loc[:,'rule_violation'] = 0\n",
    "df_p2 = df_p2.rename(columns = {'positive_example_2':'body'})\n",
    "        \n",
    "df_n1 = df_train_original[['negative_example_1','rule_violation','referral link allowed', 'Advertising allowed',\n",
    "               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n",
    "\n",
    "df_n1.loc[:,'rule_violation'] = 1\n",
    "df_n1 = df_n1.rename(columns = {'negative_example_1':'body'})\n",
    "        \n",
    "df_n2 = df_train_original[['negative_example_2','rule_violation','referral link allowed', 'Advertising allowed',\n",
    "               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n",
    "\n",
    "df_n2.loc[:,'rule_violation'] = 1\n",
    "df_n2 = df_n2.rename(columns = {'negative_example_2':'body'})\n",
    "    \n",
    "df_train_total = pd.concat([df_original,df_p1,df_p2,df_n1,df_n2], axis = 0,ignore_index=True)\n",
    "\n",
    "\n",
    "##TESTING DATA\n",
    "\n",
    "df_test_total = df_test_original[['body','referral link allowed', 'Advertising allowed',\n",
    "           'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6964cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:24.700064Z",
     "iopub.status.busy": "2025-08-11T10:07:24.699736Z",
     "iopub.status.idle": "2025-08-11T10:07:25.210714Z",
     "shell.execute_reply": "2025-08-11T10:07:25.209745Z"
    },
    "papermill": {
     "duration": 0.517717,
     "end_time": "2025-08-11T10:07:25.212396",
     "exception": false,
     "start_time": "2025-08-11T10:07:24.694679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_file = df_train_total['body'].to_list()\n",
    "    \n",
    "pattern = re.compile('https?:\\/\\/\\S+|www\\.\\S+|Https?:\\/\\/\\S+|\\S+\\.com\\S+|\\S+\\.com|\\[.*?\\]|\\S+ \\. com.*')   ## Removing URLs\n",
    "for i in range(len(text_file)):\n",
    "    text_file[i] = pattern.sub(r'',text_file[i])\n",
    "    \n",
    "pattern = re.compile('<.*?>')       ##Removing HTML rags\n",
    "for i in range(len(text_file)):\n",
    "    text_file[i] = pattern.sub(r'',text_file[i]) \n",
    "    \n",
    "pattern = re.compile('#\\S+|@\\S+|\\S+\\@\\S+|\\S+@')             ## Removing Emails and Hashtags\n",
    "for i in range(len(text_file)):\n",
    "    text_file[i] = pattern.sub(r'',text_file[i])            ### Removing username and subreddit mentions\n",
    "    \n",
    "pattern = re.compile('u\\/\\S+|r\\/\\S+')\n",
    "for i in range(len(text_file)):\n",
    "    text_file[i] = pattern.sub(r'',text_file[i])\n",
    "        \n",
    "pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "for i in range(len(text_file)):\n",
    "    text_file[i] = pattern.sub(r'',text_file[i])\n",
    "\n",
    "pattern = re.compile('\\d|\\\\n')             ##Removing Numbers & \\n spaces\n",
    "for i in range(len(text_file)):\n",
    "    text_file[i] = pattern.sub(r'',text_file[i])\n",
    "\n",
    "\n",
    "##TESTING DATA -------------------------------------------------------\n",
    "\n",
    "text_file_1 = df_test_total['body'].to_list()\n",
    "    \n",
    "pattern = re.compile('https?:\\/\\/\\S+|www\\.\\S+|Https?:\\/\\/\\S+|\\S+\\.com\\S+|\\S+\\.com|\\[.*?\\]|\\S+ \\. com.*')   ## Removing URLs\n",
    "for i in range(len(text_file_1)):\n",
    "    text_file_1[i] = pattern.sub(r'',text_file_1[i])\n",
    "    \n",
    "pattern = re.compile('<.*?>')       ##Removing HTML rags\n",
    "for i in range(len(text_file_1)):\n",
    "    text_file_1[i] = pattern.sub(r'',text_file_1[i]) \n",
    "    \n",
    "pattern = re.compile('#\\S+|@\\S+|\\S+\\@\\S+|\\S+@')             ## Removing Emails and Hashtags\n",
    "for i in range(len(text_file_1)):\n",
    "    text_file_1[i] = pattern.sub(r'',text_file_1[i])            ### Removing username and subreddit mentions\n",
    "    \n",
    "pattern = re.compile('u\\/\\S+|r\\/\\S+')\n",
    "for i in range(len(text_file_1)):\n",
    "    text_file_1[i] = pattern.sub(r'',text_file_1[i])\n",
    "        \n",
    "pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "for i in range(len(text_file_1)):\n",
    "    text_file_1[i] = pattern.sub(r'',text_file_1[i])\n",
    "\n",
    "pattern = re.compile('\\d|\\\\n')             ##Removing Numbers & \\n spaces\n",
    "for i in range(len(text_file_1)):\n",
    "    text_file_1[i] = pattern.sub(r'',text_file_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6447c040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:25.222108Z",
     "iopub.status.busy": "2025-08-11T10:07:25.221772Z",
     "iopub.status.idle": "2025-08-11T10:07:25.229753Z",
     "shell.execute_reply": "2025-08-11T10:07:25.228837Z"
    },
    "papermill": {
     "duration": 0.014764,
     "end_time": "2025-08-11T10:07:25.231445",
     "exception": false,
     "start_time": "2025-08-11T10:07:25.216681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_total = df_train_total.drop(columns = ['body'])\n",
    "df_test_total = df_test_total.drop(columns = ['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22a32ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:25.241561Z",
     "iopub.status.busy": "2025-08-11T10:07:25.241158Z",
     "iopub.status.idle": "2025-08-11T10:07:25.251071Z",
     "shell.execute_reply": "2025-08-11T10:07:25.250296Z"
    },
    "papermill": {
     "duration": 0.016758,
     "end_time": "2025-08-11T10:07:25.252792",
     "exception": false,
     "start_time": "2025-08-11T10:07:25.236034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Works perfectly\n",
    "\n",
    "x = df_train_total.drop(columns = ['rule_violation'])\n",
    "y = df_train_total['rule_violation']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size = 0.75, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241c6780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:25.263064Z",
     "iopub.status.busy": "2025-08-11T10:07:25.262728Z",
     "iopub.status.idle": "2025-08-11T10:07:31.790728Z",
     "shell.execute_reply": "2025-08-11T10:07:31.789735Z"
    },
    "papermill": {
     "duration": 6.534625,
     "end_time": "2025-08-11T10:07:31.792357",
     "exception": false,
     "start_time": "2025-08-11T10:07:25.257732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "cleaned_text = []\n",
    "preprocessed_training_text = []\n",
    "for i in range(len(df_train_total)):\n",
    "    text1 = re.sub('[^a-zA-Z]',' ',text_file[i])\n",
    "    text1 = text1.lower()\n",
    "    text1 = [lemmatizer.lemmatize(word) for word in text1 if word not in combined_stopwords]\n",
    "    cleaned_text = ''.join(text1)\n",
    "    preprocessed_training_text.append(cleaned_text)\n",
    "\n",
    "##TESTING DATA\n",
    "\n",
    "cleaned_text1 = []\n",
    "preprocessed_testing_text1 = []\n",
    "for i in range(len(df_test_total)):\n",
    "    text1 = re.sub('[^a-zA-Z]',' ',text_file_1[i])\n",
    "    text1 = text1.lower()\n",
    "    text1 = [lemmatizer.lemmatize(word) for word in text1 if word not in combined_stopwords]\n",
    "    cleaned_text1 = ''.join(text1)\n",
    "    preprocessed_testing_text1.append(cleaned_text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932ee755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:31.801917Z",
     "iopub.status.busy": "2025-08-11T10:07:31.801587Z",
     "iopub.status.idle": "2025-08-11T10:07:31.808450Z",
     "shell.execute_reply": "2025-08-11T10:07:31.807401Z"
    },
    "papermill": {
     "duration": 0.013503,
     "end_time": "2025-08-11T10:07:31.810088",
     "exception": false,
     "start_time": "2025-08-11T10:07:31.796585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_total['body'] = preprocessed_training_text\n",
    "df_test_total['body'] = preprocessed_testing_text1  ##Test file (not used right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "548d3f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:31.819847Z",
     "iopub.status.busy": "2025-08-11T10:07:31.819523Z",
     "iopub.status.idle": "2025-08-11T10:07:31.826216Z",
     "shell.execute_reply": "2025-08-11T10:07:31.825572Z"
    },
    "papermill": {
     "duration": 0.013152,
     "end_time": "2025-08-11T10:07:31.827615",
     "exception": false,
     "start_time": "2025-08-11T10:07:31.814463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df_train_total.drop(columns = ['rule_violation'])\n",
    "\n",
    "y = df_train_total['rule_violation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55179893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:31.837371Z",
     "iopub.status.busy": "2025-08-11T10:07:31.836846Z",
     "iopub.status.idle": "2025-08-11T10:07:31.840986Z",
     "shell.execute_reply": "2025-08-11T10:07:31.840227Z"
    },
    "papermill": {
     "duration": 0.010935,
     "end_time": "2025-08-11T10:07:31.842891",
     "exception": false,
     "start_time": "2025-08-11T10:07:31.831956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##Now we have to do some tokenization\n",
    "# x_train,x_test,y_train,y_test = train_test_split(x,y,train_size = 0.75, random_state = 42)\n",
    "\n",
    "# vector = TfidfVectorizer(max_features = 2500, ngram_range= (1,2))\n",
    "\n",
    "# x_train_tokenized = vector.fit_transform(x_train['body'])\n",
    "# x_test_tokenized = vector.transform(x_test['body'])\n",
    "\n",
    "# xgb = XGBClassifier()\n",
    "\n",
    "# xgb.fit(x_train_tokenized,y_train)\n",
    "\n",
    "# y_pred = xgb.predict_proba(x_test_tokenized)[:,1]\n",
    "\n",
    "# print(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f8ec0",
   "metadata": {
    "papermill": {
     "duration": 0.004294,
     "end_time": "2025-08-11T10:07:31.851680",
     "exception": false,
     "start_time": "2025-08-11T10:07:31.847386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ok,so this seems to work. Let's try to submit solution through this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c23051e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:31.861202Z",
     "iopub.status.busy": "2025-08-11T10:07:31.860458Z",
     "iopub.status.idle": "2025-08-11T10:07:33.700198Z",
     "shell.execute_reply": "2025-08-11T10:07:33.699518Z"
    },
    "papermill": {
     "duration": 1.846438,
     "end_time": "2025-08-11T10:07:33.702107",
     "exception": false,
     "start_time": "2025-08-11T10:07:31.855669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(max_features = 2500, ngram_range= (1,2))\n",
    "\n",
    "x_tokenized = vector.fit_transform(x['body'])\n",
    "test_data_tokenized = vector.transform(df_test_total['body'])\n",
    "\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb.fit(x_tokenized,y)\n",
    "\n",
    "y_pred = xgb.predict_proba(test_data_tokenized)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7916679b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:33.713711Z",
     "iopub.status.busy": "2025-08-11T10:07:33.713360Z",
     "iopub.status.idle": "2025-08-11T10:07:33.732758Z",
     "shell.execute_reply": "2025-08-11T10:07:33.731729Z"
    },
    "papermill": {
     "duration": 0.027679,
     "end_time": "2025-08-11T10:07:33.734921",
     "exception": false,
     "start_time": "2025-08-11T10:07:33.707242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv')\n",
    "\n",
    "\n",
    "submission['rule_violation'] = np.round(y_pred,2)\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False, columns=[\"row_id\", \"rule_violation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66a9e333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:07:33.745232Z",
     "iopub.status.busy": "2025-08-11T10:07:33.744900Z",
     "iopub.status.idle": "2025-08-11T10:07:33.766416Z",
     "shell.execute_reply": "2025-08-11T10:07:33.765488Z"
    },
    "papermill": {
     "duration": 0.028571,
     "end_time": "2025-08-11T10:07:33.768127",
     "exception": false,
     "start_time": "2025-08-11T10:07:33.739556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2029</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2031</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2032</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2033</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2034</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2035</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2036</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2037</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2038</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  rule_violation\n",
       "0    2029            0.67\n",
       "1    2030            0.48\n",
       "2    2031            0.39\n",
       "3    2032            0.77\n",
       "4    2033            0.22\n",
       "5    2034            0.62\n",
       "6    2035            0.67\n",
       "7    2036            0.63\n",
       "8    2037            0.79\n",
       "9    2038            0.22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ebfe88",
   "metadata": {
    "papermill": {
     "duration": 0.003956,
     "end_time": "2025-08-11T10:07:33.776621",
     "exception": false,
     "start_time": "2025-08-11T10:07:33.772665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "sourceId": 94635,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.755691,
   "end_time": "2025-08-11T10:07:35.004344",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-11T10:07:14.248653",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth',None)\nimport re\n## Now tokenization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport spacy\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dense, Embedding, Concatenate, Input, LSTM\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.layers import SimpleRNN, Dense,Reshape, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Attention, Flatten, GlobalAveragePooling1D,BatchNormalization, LayerNormalization, Bidirectional, MultiHeadAttention, Add\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nspacy_stopwords = nlp.Defaults.stop_words\nnltk_stopwords = set(stopwords.words('english'))\ncombined_stopwords = spacy_stopwords.union(nltk_stopwords)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/train.csv')\ndf_test = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n#b = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:43:18.018974Z","iopub.execute_input":"2025-08-03T06:43:18.019302Z","iopub.status.idle":"2025-08-03T06:43:18.061473Z","shell.execute_reply.started":"2025-08-03T06:43:18.019278Z","shell.execute_reply":"2025-08-03T06:43:18.060658Z"}},"outputs":[],"execution_count":137},{"cell_type":"markdown","source":"### Since testing data has only (10,8) shape. We will report training from MY own training class, then train ALL the training data on that, and then Predict the testing dataframe on that. So code pipelines should be written. ","metadata":{}},{"cell_type":"markdown","source":"## We need to match row_id with Probability of being in one class.","metadata":{}},{"cell_type":"code","source":"a.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:29:58.182412Z","iopub.execute_input":"2025-08-03T06:29:58.182757Z","iopub.status.idle":"2025-08-03T06:29:58.188586Z","shell.execute_reply.started":"2025-08-03T06:29:58.182726Z","shell.execute_reply":"2025-08-03T06:29:58.187881Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"(10, 6)"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"def dataset_basics(df):\n    print(f'Number of empty rows \\n {df.isna().sum()} \\n')\n    print(f'Number of duplicate rows {df.duplicated().sum()} \\n')\n    print(f'\\n Dtypes and other info \\n {df.info()} \\n')\n    print(f'Shape of the dataframe {df.shape}')\n\ndataset_basics(df_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:29:58.330007Z","iopub.execute_input":"2025-08-03T06:29:58.330617Z","iopub.status.idle":"2025-08-03T06:29:58.349824Z","shell.execute_reply.started":"2025-08-03T06:29:58.330591Z","shell.execute_reply":"2025-08-03T06:29:58.348965Z"}},"outputs":[{"name":"stdout","text":"Number of empty rows \n row_id                0\nbody                  0\nrule                  0\nsubreddit             0\npositive_example_1    0\npositive_example_2    0\nnegative_example_1    0\nnegative_example_2    0\nrule_violation        0\ndtype: int64 \n\nNumber of duplicate rows 0 \n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2029 entries, 0 to 2028\nData columns (total 9 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   row_id              2029 non-null   int64 \n 1   body                2029 non-null   object\n 2   rule                2029 non-null   object\n 3   subreddit           2029 non-null   object\n 4   positive_example_1  2029 non-null   object\n 5   positive_example_2  2029 non-null   object\n 6   negative_example_1  2029 non-null   object\n 7   negative_example_2  2029 non-null   object\n 8   rule_violation      2029 non-null   int64 \ndtypes: int64(2), object(7)\nmemory usage: 142.8+ KB\n\n Dtypes and other info \n None \n\nShape of the dataframe (2029, 9)\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"df_train['subreddit'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:29:58.485534Z","iopub.execute_input":"2025-08-03T06:29:58.486443Z","iopub.status.idle":"2025-08-03T06:29:58.492070Z","shell.execute_reply.started":"2025-08-03T06:29:58.486413Z","shell.execute_reply":"2025-08-03T06:29:58.491143Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}],"execution_count":74},{"cell_type":"markdown","source":"## There are 100 unique subreddits.","metadata":{}},{"cell_type":"code","source":"df_train['rule_violation'].value_counts()/df_train.shape[0] * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:29:58.781505Z","iopub.execute_input":"2025-08-03T06:29:58.781803Z","iopub.status.idle":"2025-08-03T06:29:58.789297Z","shell.execute_reply.started":"2025-08-03T06:29:58.781783Z","shell.execute_reply":"2025-08-03T06:29:58.788533Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"rule_violation\n1    50.813208\n0    49.186792\nName: count, dtype: float64"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:00.083850Z","iopub.execute_input":"2025-08-03T06:30:00.084961Z","iopub.status.idle":"2025-08-03T06:30:00.096139Z","shell.execute_reply.started":"2025-08-03T06:30:00.084919Z","shell.execute_reply":"2025-08-03T06:30:00.095276Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"   row_id  \\\n0       0   \n1       1   \n2       2   \n3       3   \n4       4   \n\n                                                                                                                                                                                                                                                                                                                             body  \\\n0                                                                                                                                                                                                                                                                     Banks don't want you to know this! Click here to know more!   \n1                                                                                                                                                                                                                                     SD Stream [ ENG Link 1] (http://www.sportsstreams247.com/astra-giurgiu-vs-fc-austria-wien/)   \n2                                                                                                                                                                                                                                                                       Lol. Try appealing the ban and say you won't do it again.   \n3                                                                                                                                                                                                                                                     she will come your home open her legs with  and  you http://sh.ors.it/PALI2   \n4  code free tyrande --->>> [Imgur](http://i.imgur.com/KlvssCl.png)\\n\\nfor you and your friend 2 codes for 4 dollars https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=UN4E27AG7BWKS\\n\\n2$... buy one directly from here: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=VP3S5HQRE7T7E\\n   \n\n                                                                                                      rule  \\\n0  No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.   \n1  No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.   \n2                                                   No legal advice: Do not offer or request legal advice.   \n3  No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.   \n4  No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.   \n\n       subreddit  \\\n0     Futurology   \n1  soccerstreams   \n2   pcmasterrace   \n3            sex   \n4    hearthstone   \n\n                                                                                                                                                                                                                                                                                                                         positive_example_1  \\\n0                                                                                                             If you could tell your younger self something different about sex, what would that be?\\n\\ni AM IN A CONTEST TO WIN FUNDING FOR MY SEX POSITIVE FILM: VOTE HERE:\\n\\nhttp://sheknows.offerpop.com/campaign/813112/entry/v144417   \n1                                                                                                                                                                                                                                                            [I wanna kiss you all over! Stunning!](http://www.oilflush.life/2017/01/26/6/)   \n2                                                                                                                                                          Don't break up with him or call the cops.  If you are willing to get beat up by him to stay with him, he is obviously a real winner and you know it, so you shouldn't leave him.   \n3                                                                                                                                                                                                                                                                    Selling Tyrande codes for 3€ to paypal. PM. \\nhttp://imgur.com/a/IMARW   \n4   wow!! amazing reminds me of the old days.Well Do you desire a great spell caster and a herbal doctor to help you solve any problem you are going through? i am a proud testimony of what king favour solution temple has offered me. Contact him now at kingfavoursolutiontemple@yahoo.com You will be the next to testify.bye everyone   \n\n                                                                                                                                                             positive_example_2  \\\n0                                                                                                        hunt for lady for jack off in neighbourhood http://url.inmusi.com/gakq   \n1  LOLGA.COM is One of the First Professional Online Gold sites. By Now, As A Game Gold Seller, we've over more than 5 yrs Of Experience And Can Pass That On To Our Customers.   \n2                                            It'll be dismissed: https://en.wikipedia.org/wiki/New_York_Times_Co._v._Sullivan\\n\\nThe first amendment law here is SUPER settled.   \n3                                                                                  tight pussy watch for your cock get her at this point http://macanasmagazine.com/yourls/hnof   \n4                                                                                                                           seek for lady for sex in around http://p77.pl/12yb9   \n\n                                                                                                                                                                                                                                                                                                                                                     negative_example_1  \\\n0  Watch Golden Globe Awards 2017 Live Online in HD Coverage without ADS (VIP STREAMS)\\n=\\n\\nHD STREAM QUALITY >>> [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&t=215858)\\n=\\n\\nHD BROADCASTING QUALITY >>> [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&t=215858)\\n=\\n\\nMobile Compatibility: YES\\n=\\n\\nNO ADS | NO ADS | ADS\\n=\\n   \n1                                                                                                                                              #Rapper \\n🚨Straight Outta Cross Keys SC 🚨YouTube Search Beanie 864 Click Link BELOW To Hear Hit Single\\n  \"Ah Man\" \\n Beanie 864 FEAT King Kota \\n (King Kota Is Only 15!) Lit 🌡🔥👍💵💯Fr Fr \\nhttps://youtu.be/tLqbV1Jmt5Y   \n2                                                                                                                                                                                                                                                      Where is there a site that still works where you can jump the GPS. Is there a FAQ to do this with iPhone or Mac?   \n3                                                                                                                                                                                                                                                                                              NSFW(obviously) http://spankbang.com/iy3u/video/marica+hase+mirrors+edge   \n4                                                                                                                                                                                                                                                                           must be watch movie https://sites.google.com/site/greatescape1963xx/-jagten-2012-full-movie   \n\n                                                                                                                                                                                                                                                                                                                                                                                                 negative_example_2  \\\n0                                                                                                                                                                                                                                                                                                         DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/STREAM:\\n\\nhttp://music.theblacksmithed.com/download/birds/   \n1  [15 Amazing Hidden Features Of Google Search You Probably Don’t Know](http://www.madpeoples.com/2017/01/02  No one would argue the fact that Google is one of the most useful sihttp://www.madpeoples.com/2016/12/31/15-amazing-hidden-features-of-google-search-you-probably-dont-know/tes on the Internet. Unfortunately, most people only use about...?utm_source=reddit&utm_campaign=samreen&utm_medium=cpc)   \n2                                                                                                                                                                                                                                                       Because this statement of his is true. It isn't freedom of the press, it's libel. And because of this, your post serves as a promotion for Trump. Reported.   \n3                                                                                                                                                                                                                                                                                                                                           Good News ::Download WhatsApp 2.16.230 APK for Android – Latest Version   \n4                                                                                                                                                                                                                                                                                                        We're streaming Pokemon Veitnamese Crystal RIGHT NOW, come watch https://www.twitch.tv/adandyguyinspace55.   \n\n   rule_violation  \n0               0  \n1               0  \n2               1  \n3               1  \n4               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>body</th>\n      <th>rule</th>\n      <th>subreddit</th>\n      <th>positive_example_1</th>\n      <th>positive_example_2</th>\n      <th>negative_example_1</th>\n      <th>negative_example_2</th>\n      <th>rule_violation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Banks don't want you to know this! Click here to know more!</td>\n      <td>No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.</td>\n      <td>Futurology</td>\n      <td>If you could tell your younger self something different about sex, what would that be?\\n\\ni AM IN A CONTEST TO WIN FUNDING FOR MY SEX POSITIVE FILM: VOTE HERE:\\n\\nhttp://sheknows.offerpop.com/campaign/813112/entry/v144417</td>\n      <td>hunt for lady for jack off in neighbourhood http://url.inmusi.com/gakq</td>\n      <td>Watch Golden Globe Awards 2017 Live Online in HD Coverage without ADS (VIP STREAMS)\\n=\\n\\nHD STREAM QUALITY &gt;&gt;&gt; [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&amp;t=215858)\\n=\\n\\nHD BROADCASTING QUALITY &gt;&gt;&gt; [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&amp;t=215858)\\n=\\n\\nMobile Compatibility: YES\\n=\\n\\nNO ADS | NO ADS | ADS\\n=\\n</td>\n      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/STREAM:\\n\\nhttp://music.theblacksmithed.com/download/birds/</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>SD Stream [ ENG Link 1] (http://www.sportsstreams247.com/astra-giurgiu-vs-fc-austria-wien/)</td>\n      <td>No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.</td>\n      <td>soccerstreams</td>\n      <td>[I wanna kiss you all over! Stunning!](http://www.oilflush.life/2017/01/26/6/)</td>\n      <td>LOLGA.COM is One of the First Professional Online Gold sites. By Now, As A Game Gold Seller, we've over more than 5 yrs Of Experience And Can Pass That On To Our Customers.</td>\n      <td>#Rapper \\n🚨Straight Outta Cross Keys SC 🚨YouTube Search Beanie 864 Click Link BELOW To Hear Hit Single\\n  \"Ah Man\" \\n Beanie 864 FEAT King Kota \\n (King Kota Is Only 15!) Lit 🌡🔥👍💵💯Fr Fr \\nhttps://youtu.be/tLqbV1Jmt5Y</td>\n      <td>[15 Amazing Hidden Features Of Google Search You Probably Don’t Know](http://www.madpeoples.com/2017/01/02  No one would argue the fact that Google is one of the most useful sihttp://www.madpeoples.com/2016/12/31/15-amazing-hidden-features-of-google-search-you-probably-dont-know/tes on the Internet. Unfortunately, most people only use about...?utm_source=reddit&amp;utm_campaign=samreen&amp;utm_medium=cpc)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Lol. Try appealing the ban and say you won't do it again.</td>\n      <td>No legal advice: Do not offer or request legal advice.</td>\n      <td>pcmasterrace</td>\n      <td>Don't break up with him or call the cops.  If you are willing to get beat up by him to stay with him, he is obviously a real winner and you know it, so you shouldn't leave him.</td>\n      <td>It'll be dismissed: https://en.wikipedia.org/wiki/New_York_Times_Co._v._Sullivan\\n\\nThe first amendment law here is SUPER settled.</td>\n      <td>Where is there a site that still works where you can jump the GPS. Is there a FAQ to do this with iPhone or Mac?</td>\n      <td>Because this statement of his is true. It isn't freedom of the press, it's libel. And because of this, your post serves as a promotion for Trump. Reported.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>she will come your home open her legs with  and  you http://sh.ors.it/PALI2</td>\n      <td>No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.</td>\n      <td>sex</td>\n      <td>Selling Tyrande codes for 3€ to paypal. PM. \\nhttp://imgur.com/a/IMARW</td>\n      <td>tight pussy watch for your cock get her at this point http://macanasmagazine.com/yourls/hnof</td>\n      <td>NSFW(obviously) http://spankbang.com/iy3u/video/marica+hase+mirrors+edge</td>\n      <td>Good News ::Download WhatsApp 2.16.230 APK for Android – Latest Version</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgur.com/KlvssCl.png)\\n\\nfor you and your friend 2 codes for 4 dollars https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=UN4E27AG7BWKS\\n\\n2$... buy one directly from here: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=VP3S5HQRE7T7E\\n</td>\n      <td>No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.</td>\n      <td>hearthstone</td>\n      <td>wow!! amazing reminds me of the old days.Well Do you desire a great spell caster and a herbal doctor to help you solve any problem you are going through? i am a proud testimony of what king favour solution temple has offered me. Contact him now at kingfavoursolutiontemple@yahoo.com You will be the next to testify.bye everyone</td>\n      <td>seek for lady for sex in around http://p77.pl/12yb9</td>\n      <td>must be watch movie https://sites.google.com/site/greatescape1963xx/-jagten-2012-full-movie</td>\n      <td>We're streaming Pokemon Veitnamese Crystal RIGHT NOW, come watch https://www.twitch.tv/adandyguyinspace55.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"markdown","source":"## Rule violated vs obeyed ratio is almost 1 to 1.\n\n## Let's prepare the Rules first.","metadata":{}},{"cell_type":"code","source":"split_df = df_train['rule'].str.split(',', expand=True)\nsplit_df.fillna('0',inplace=True)\nsplit_df.columns = ['rule 1','rule 2','rule 3','rule 4']\nsplit_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:00.397330Z","iopub.execute_input":"2025-08-03T06:30:00.397598Z","iopub.status.idle":"2025-08-03T06:30:00.413345Z","shell.execute_reply.started":"2025-08-03T06:30:00.397580Z","shell.execute_reply":"2025-08-03T06:30:00.412596Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"                                                   rule 1           rule 2  \\\n0                                    No Advertising: Spam   referral links   \n1                                    No Advertising: Spam   referral links   \n2  No legal advice: Do not offer or request legal advice.                0   \n3                                    No Advertising: Spam   referral links   \n4                                    No Advertising: Spam   referral links   \n\n                     rule 3                                     rule 4  \n0   unsolicited advertising   and promotional content are not allowed.  \n1   unsolicited advertising   and promotional content are not allowed.  \n2                         0                                          0  \n3   unsolicited advertising   and promotional content are not allowed.  \n4   unsolicited advertising   and promotional content are not allowed.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rule 1</th>\n      <th>rule 2</th>\n      <th>rule 3</th>\n      <th>rule 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No Advertising: Spam</td>\n      <td>referral links</td>\n      <td>unsolicited advertising</td>\n      <td>and promotional content are not allowed.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>No Advertising: Spam</td>\n      <td>referral links</td>\n      <td>unsolicited advertising</td>\n      <td>and promotional content are not allowed.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No legal advice: Do not offer or request legal advice.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Advertising: Spam</td>\n      <td>referral links</td>\n      <td>unsolicited advertising</td>\n      <td>and promotional content are not allowed.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No Advertising: Spam</td>\n      <td>referral links</td>\n      <td>unsolicited advertising</td>\n      <td>and promotional content are not allowed.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"## Allowed is 1 and forbidden is 0 (Referral links)\nsplit_df['rule 2'] = split_df['rule 2'].apply(lambda x : 1 if 'referral links' in str(x).lower() else 0)\nsplit_df = split_df.rename(columns = {'rule 2':'referral link allowed'})\n\n\n## Allowed is 1 and not allowed is 0. (Legal Advices)\nsplit_df['legal_advice_allowed'] = split_df['rule 1'].apply(lambda x: 0 if 'legal' in str(x).lower() else 1)\n\n\n## Allowed is 1 and not allowed is 0. (promotions) \nsplit_df['rule 4'] = split_df['rule 4'].apply(lambda x: 0 if 'promotional' in str(x).lower() else 1)\nsplit_df = split_df.rename(columns = {'rule 4':'Promotions allowed'})\n\n\n## Allowed is 1 and not allowed is 0. (Advertising) \nsplit_df['rule 3'] = split_df['rule 3'].apply(lambda x: 0 if 'advertising' in str(x).lower() else 1)\nsplit_df = split_df.rename(columns = {'rule 3':'Advertising allowed'})\n\n\n## Allowed is 1 and not allowed is 0. (Spam) \n## Spam 1 doesn't mean that it's allowed. It means that it's not relevant. \n\n## IN following lines, we split dataframe from original to deal with spam part.\nsplit_df_1 = split_df['rule 1'].str.split(':',expand=True)\nsplit_df = split_df.drop(columns = ['rule 1'])\n\nsplit_df_1.columns = ['Advert','spam']\nsplit_df_1 = split_df_1.drop(columns = ['Advert'])\n\nsplit_df_1['spam allowed'] = split_df_1['spam'].apply(lambda x: 0 if 'spam' in str(x).lower() else 1)\nsplit_df['spam allowed'] = split_df_1['spam allowed']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:00.545194Z","iopub.execute_input":"2025-08-03T06:30:00.545920Z","iopub.status.idle":"2025-08-03T06:30:00.573629Z","shell.execute_reply.started":"2025-08-03T06:30:00.545894Z","shell.execute_reply":"2025-08-03T06:30:00.572635Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Both Legal advice and Spam are mututally exclusive. In model, remember to specify it.","metadata":{}},{"cell_type":"code","source":"split_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:03.305199Z","iopub.execute_input":"2025-08-03T06:30:03.305758Z","iopub.status.idle":"2025-08-03T06:30:03.314069Z","shell.execute_reply.started":"2025-08-03T06:30:03.305730Z","shell.execute_reply":"2025-08-03T06:30:03.313246Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"   referral link allowed  Advertising allowed  Promotions allowed  \\\n0                      1                    0                   0   \n1                      1                    0                   0   \n2                      0                    1                   1   \n3                      1                    0                   0   \n4                      1                    0                   0   \n\n   legal_advice_allowed  spam allowed  \n0                     1             0  \n1                     1             0  \n2                     0             1  \n3                     1             0  \n4                     1             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>referral link allowed</th>\n      <th>Advertising allowed</th>\n      <th>Promotions allowed</th>\n      <th>legal_advice_allowed</th>\n      <th>spam allowed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"df = df_train.copy()\n\nfor i in split_df.columns:\n    df[i] = split_df[i]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:03.523509Z","iopub.execute_input":"2025-08-03T06:30:03.523906Z","iopub.status.idle":"2025-08-03T06:30:03.531343Z","shell.execute_reply.started":"2025-08-03T06:30:03.523881Z","shell.execute_reply":"2025-08-03T06:30:03.530474Z"}},"outputs":[],"execution_count":80},{"cell_type":"markdown","source":"## Rules are preapred. \n\n## Next we work with examples.\n\n## So we have examples of data that violate and those who do not voilate the rule. We can take them in seperate datasets, add target values to them. Concatinate them to original dataset and then using all of that, train our model.\n\n## Let's seperate in the following order\n* ### Original: - df_original \n* ### 1st +ve: - df_p1 \n* ### 2nd +ve: - df_p2 \n* ### 1st -ve: - df_n1 \n* ### 2nd -ve: - df_n2\n\n## Seems all fine.","metadata":{}},{"cell_type":"code","source":"df_original = df[['body', 'rule_violation','referral link allowed', 'Advertising allowed',\n       'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n\ndf_p1 = df[['positive_example_1','rule_violation','referral link allowed', 'Advertising allowed',\n       'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\ndf_p1.loc[:,'rule_violation'] = 0\ndf_p1 = df_p1.rename(columns = {'positive_example_1':'body'})\n\ndf_p2 = df[['positive_example_2','rule_violation','referral link allowed', 'Advertising allowed',\n       'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\ndf_p2.loc[:,'rule_violation'] = 0\ndf_p2 = df_p2.rename(columns = {'positive_example_2':'body'})\n\ndf_n1 = df[['negative_example_1','rule_violation','referral link allowed', 'Advertising allowed',\n       'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\ndf_n1.loc[:,'rule_violation'] = 1\ndf_n1 = df_n1.rename(columns = {'negative_example_1':'body'})\n\ndf_n2 = df[['negative_example_2','rule_violation','referral link allowed', 'Advertising allowed',\n       'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\ndf_n2.loc[:,'rule_violation'] = 1\ndf_n2 = df_n2.rename(columns = {'negative_example_2':'body'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:06.590227Z","iopub.execute_input":"2025-08-03T06:30:06.590534Z","iopub.status.idle":"2025-08-03T06:30:06.606879Z","shell.execute_reply.started":"2025-08-03T06:30:06.590508Z","shell.execute_reply":"2025-08-03T06:30:06.606035Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"df_total = pd.concat([df_original,df_p1,df_p2,df_n1,df_n2], axis = 0,ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:07.324234Z","iopub.execute_input":"2025-08-03T06:30:07.324525Z","iopub.status.idle":"2025-08-03T06:30:07.331081Z","shell.execute_reply.started":"2025-08-03T06:30:07.324504Z","shell.execute_reply":"2025-08-03T06:30:07.330143Z"}},"outputs":[],"execution_count":82},{"cell_type":"markdown","source":"## Ok, now let's strip comment content and sophisticate it.\n\n### WIll text data have anything to do with numbers. I don't think even if we exclude them, there will be much impact. \n### There are HTML tags as well.\n### So there are links. short advirtisements in brackets. ","metadata":{}},{"cell_type":"code","source":"text1 = df_total['body'].to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:08.441287Z","iopub.execute_input":"2025-08-03T06:30:08.441569Z","iopub.status.idle":"2025-08-03T06:30:08.446161Z","shell.execute_reply.started":"2025-08-03T06:30:08.441549Z","shell.execute_reply":"2025-08-03T06:30:08.445283Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_total.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:10.101353Z","iopub.execute_input":"2025-08-03T06:30:10.101706Z","iopub.status.idle":"2025-08-03T06:30:10.111763Z","shell.execute_reply.started":"2025-08-03T06:30:10.101681Z","shell.execute_reply":"2025-08-03T06:30:10.110960Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"                                                                                                                                                                                                                                                                                                                             body  \\\n0                                                                                                                                                                                                                                                                     Banks don't want you to know this! Click here to know more!   \n1                                                                                                                                                                                                                                     SD Stream [ ENG Link 1] (http://www.sportsstreams247.com/astra-giurgiu-vs-fc-austria-wien/)   \n2                                                                                                                                                                                                                                                                       Lol. Try appealing the ban and say you won't do it again.   \n3                                                                                                                                                                                                                                                     she will come your home open her legs with  and  you http://sh.ors.it/PALI2   \n4  code free tyrande --->>> [Imgur](http://i.imgur.com/KlvssCl.png)\\n\\nfor you and your friend 2 codes for 4 dollars https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=UN4E27AG7BWKS\\n\\n2$... buy one directly from here: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=VP3S5HQRE7T7E\\n   \n\n   rule_violation  referral link allowed  Advertising allowed  \\\n0               0                      1                    0   \n1               0                      1                    0   \n2               1                      0                    1   \n3               1                      1                    0   \n4               1                      1                    0   \n\n   Promotions allowed  legal_advice_allowed  spam allowed  \n0                   0                     1             0  \n1                   0                     1             0  \n2                   1                     0             1  \n3                   0                     1             0  \n4                   0                     1             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>rule_violation</th>\n      <th>referral link allowed</th>\n      <th>Advertising allowed</th>\n      <th>Promotions allowed</th>\n      <th>legal_advice_allowed</th>\n      <th>spam allowed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Banks don't want you to know this! Click here to know more!</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SD Stream [ ENG Link 1] (http://www.sportsstreams247.com/astra-giurgiu-vs-fc-austria-wien/)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lol. Try appealing the ban and say you won't do it again.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>she will come your home open her legs with  and  you http://sh.ors.it/PALI2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgur.com/KlvssCl.png)\\n\\nfor you and your friend 2 codes for 4 dollars https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=UN4E27AG7BWKS\\n\\n2$... buy one directly from here: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=VP3S5HQRE7T7E\\n</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"def remove_urls(text):\n    pattern = re.compile('https?:\\/\\/\\S+|www\\.\\S+|Https?:\\/\\/\\S+|\\S+\\.com\\S+|\\S+\\.com|\\[.*?\\]|\\S+ \\. com.*')\n    for i in range(len(text)):\n        text[i] = pattern.sub(r'',text[i])\n    return text\n\ntext1 = remove_urls(text1)\n\n##Can be modified\n\n### Removing HTML tags\ndef remove_html(text):\n    pattern = re.compile('<.*?>')\n    for i in range(len(text)):\n        text[i] = pattern.sub(r'',text[i])\n    return text\n\ntext1 = remove_html(text1)\n\n## Works perfectly\n\n\n### Removing Emails and hashtags\n\ndef remove_mail_hashtag(text):\n    pattern = re.compile('#\\S+|@\\S+|\\S+\\@\\S+|\\S+@')\n    for i in range(len(text)):\n        text[i] = pattern.sub(r'',text[i])\n    return text\n\ntext1 = remove_mail_hashtag(text1)\n\n#Works perfectly\n\n### Removing username and subreddit mentions\n\ndef remove_username_subreddit(text):\n    pattern = re.compile('u\\/\\S+|r\\/\\S+')\n    for i in range(len(text)):\n        text[i] = pattern.sub(r'',text[i])\n    return text\n\ntext1 = remove_username_subreddit(text1)\n\n## Works perfectly\n\n### Removing emojis and more alike.\n\ndef remove_emojis(text):\n    pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    for i in range(len(text)):\n        text[i] = pattern.sub(r'',text[i])\n    return text\n\ntext1 = remove_emojis(text1)\n\n##Works perfectly\n\n### Removing Numbers & \\n spaces\n\ndef remove_numbers(text):\n    pattern = re.compile('\\d|\\\\n')\n    for i in range(len(text)):\n        text[i] = pattern.sub(r'',text[i])\n    return text\n\ntext12 = remove_numbers(text1)\n\n## Works perfectly since all currency and special characters will be removed afterwards. ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:10.297554Z","iopub.execute_input":"2025-08-03T06:30:10.298455Z","iopub.status.idle":"2025-08-03T06:30:10.784008Z","shell.execute_reply.started":"2025-08-03T06:30:10.298420Z","shell.execute_reply":"2025-08-03T06:30:10.783276Z"}},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":"### Removing urls","metadata":{}},{"cell_type":"code","source":"df_total['body'] = text12\nx = df_total.drop(columns = ['rule_violation'])\ny = df_total['rule_violation']\n\nx_train_pre,x_test_pre,y_train,y_test = train_test_split(x,y,train_size = 0.75, random_state = 42)\n\n\ntraining_text = x_train_pre['body'].to_list()\ntesting_text = x_test_pre['body'].to_list()\n\n\nx_train_pre = x_train_pre.drop(columns = ['body'])\nx_test_pre = x_test_pre.drop(columns = ['body'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:13.423324Z","iopub.execute_input":"2025-08-03T06:30:13.423627Z","iopub.status.idle":"2025-08-03T06:30:13.437619Z","shell.execute_reply.started":"2025-08-03T06:30:13.423603Z","shell.execute_reply":"2025-08-03T06:30:13.436697Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:14.853182Z","iopub.execute_input":"2025-08-03T06:30:14.853470Z","iopub.status.idle":"2025-08-03T06:30:14.857559Z","shell.execute_reply.started":"2025-08-03T06:30:14.853447Z","shell.execute_reply":"2025-08-03T06:30:14.856785Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"##Training data cleaning\n\ncleaned_text = []\npreprocessed_training_text = []\nfor i in range(len(x_train_pre)):\n    text1 = re.sub('[^a-zA-Z]',' ',training_text[i])\n    text1 = text1.lower()\n    text1 = [lemmatizer.lemmatize(word) for word in text1 if word not in combined_stopwords]\n    cleaned_text = ''.join(text1)\n    preprocessed_training_text.append(cleaned_text)\n\n##Testing data cleaning\n\ncleaned_text1 = []\npreprocessed_testing_text = []\nfor i in range(len(x_test_pre)):\n    text1 = re.sub('[^a-zA-Z]',' ',testing_text[i])\n    text1 = text1.lower()\n    text1 = [lemmatizer.lemmatize(word) for word in text1 if word not in combined_stopwords]\n    cleaned_text1 = ''.join(text1)\n    preprocessed_testing_text.append(cleaned_text1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:15.049273Z","iopub.execute_input":"2025-08-03T06:30:15.049553Z","iopub.status.idle":"2025-08-03T06:30:18.243688Z","shell.execute_reply.started":"2025-08-03T06:30:15.049531Z","shell.execute_reply":"2025-08-03T06:30:18.242872Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"type(preprocessed_training_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:32.222799Z","iopub.execute_input":"2025-08-03T06:30:32.223149Z","iopub.status.idle":"2025-08-03T06:30:32.228640Z","shell.execute_reply.started":"2025-08-03T06:30:32.223123Z","shell.execute_reply":"2025-08-03T06:30:32.227946Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"token = Tokenizer(num_words = 5000, oov_token='<OOV>')\n##training text tokenization and padding\n\ntoken.fit_on_texts(preprocessed_training_text)\nmax_length = max(len(i.split()) for i in preprocessed_training_text)\ntraining_sequence = token.texts_to_sequences(preprocessed_training_text)\nx_train = pad_sequences(training_sequence, maxlen=max_length, padding='post')\n\n\n##Testing Text tokenization and padding\n\ntesting_sequence = token.texts_to_sequences(preprocessed_testing_text)\nx_test = pad_sequences(testing_sequence, maxlen=max_length, padding='post')\nmax_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:35.467073Z","iopub.execute_input":"2025-08-03T06:30:35.467372Z","iopub.status.idle":"2025-08-03T06:30:35.788636Z","shell.execute_reply.started":"2025-08-03T06:30:35.467351Z","shell.execute_reply":"2025-08-03T06:30:35.787638Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"83"},"metadata":{}}],"execution_count":91},{"cell_type":"markdown","source":"### ROC AUC curve\n","metadata":{}},{"cell_type":"code","source":"## Feature dataset input preprocessing\nfeature_input = Input(shape=(5,), name = 'other_feature')\ny = Dense(64, activation='relu')(feature_input)\ny = BatchNormalization()(y)\ny = Dropout(0.3)(y)\ny = Dense(64, activation='relu')(y)\n\n## Text input preprocessing\ntext_input = Input(shape=(83,), name='text_input')\nembedding = Embedding(input_dim = 5000, output_dim = 128)(text_input)\nx1 = Bidirectional(LSTM(128, return_sequences=True))(embedding)\n\n# Multi-Head Attention for better context\nx2 = MultiHeadAttention(num_heads=4, key_dim=64)(x1, x1)\n\n# Combine Attention output with LSTM via Residual Connection\nx2 = Add()([x1, x2])  # residual connection\n\n# Pooling to flatten sequence\nx = GlobalAveragePooling1D()(x2)\n\n\ncombined = Concatenate()([x,y])\nrnn1 = Dense(128, activation='relu')(combined)\nrnn2 = Dense(64, activation='relu')(rnn1)\ndense3 = Dense(32, activation='relu')(rnn2)\noutput = Dense(1, activation='sigmoid')(dense3)\n\nmodel = Model(inputs=[text_input, feature_input], outputs=output)\nadam = Adam(learning_rate = 0.001)\nmodel.compile(optimizer=adam, loss='binary_crossentropy', metrics=[AUC(curve='ROC', name='roc_auc')])\n## This architecture achieved loss: 0.4561 - roc_auc: 0.8632 - val_loss: 0.5426 - val_roc_auc: 0.8094 after 20 iterations.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:40.624570Z","iopub.execute_input":"2025-08-03T06:30:40.624931Z","iopub.status.idle":"2025-08-03T06:30:40.783884Z","shell.execute_reply.started":"2025-08-03T06:30:40.624904Z","shell.execute_reply":"2025-08-03T06:30:40.783160Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"type(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:43:08.778760Z","iopub.execute_input":"2025-08-03T06:43:08.779361Z","iopub.status.idle":"2025-08-03T06:43:08.784195Z","shell.execute_reply.started":"2025-08-03T06:43:08.779332Z","shell.execute_reply":"2025-08-03T06:43:08.783362Z"}},"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"pandas.core.series.Series"},"metadata":{}}],"execution_count":136},{"cell_type":"code","source":"\nhistory = model.fit(\n    {'text_input': x_train, 'other_feature': x_train_pre},\n    y_train,\n    epochs=25, validation_data=(\n        {'text_input': x_test, 'other_feature': x_test_pre},\n        y_test\n    ),\n    batch_size=64,verbose = 1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:30:43.082873Z","iopub.execute_input":"2025-08-03T06:30:43.083178Z","iopub.status.idle":"2025-08-03T06:30:43.262937Z","shell.execute_reply.started":"2025-08-03T06:30:43.083158Z","shell.execute_reply":"2025-08-03T06:30:43.261852Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2477919808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'text_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'other_feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train_pre\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     epochs=25, validation_data=(\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'text_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'other_feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test_pre\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_2\" is incompatible with the layer: expected shape=(None, 213), found shape=(None, 83)"],"ename":"ValueError","evalue":"Input 0 of layer \"functional_2\" is incompatible with the layer: expected shape=(None, 213), found shape=(None, 83)","output_type":"error"}],"execution_count":93},{"cell_type":"markdown","source":"### This architecture achieved  loss: 0.3812 - roc_auc: 0.9027 - val_loss: 0.5281 - val_roc_auc: 0.8164 after 25 iterations.\n### we can train our model and use out testing data on it. ","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict({'text_input': x_test, 'other_feature': x_test_pre})\nfrom sklearn.metrics import roc_auc_score\nroc_auc_test = roc_auc_score(y_test, y_pred)\nprint(f\"Test ROC-AUC: {roc_auc_test:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T16:49:39.144306Z","iopub.execute_input":"2025-08-02T16:49:39.144677Z","iopub.status.idle":"2025-08-02T16:49:40.874013Z","shell.execute_reply.started":"2025-08-02T16:49:39.144648Z","shell.execute_reply":"2025-08-02T16:49:40.873378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def training_data_prep(dataframe):\n    df = dataframe['rule'].str.split(',',expand=True)\n    df.fillna('0',inplace=True)\n    df.columns = ['rule 1','rule 2','rule 3','rule 4']\n    ## till here it works perfectly\n    df['rule 2'] = df['rule 2'].apply(lambda x : 1 if 'referral links' in str(x).lower() else 0)\n    df = df.rename(columns = {'rule 2':'referral link allowed'})\n    #column 0 (legal_advice)\n    df['legal_advice_allowed'] = df['rule 1'].apply(lambda x: 0 if 'legal' in str(x).lower() else 1)\n    #column 1\n    df['rule 4'] = df['rule 4'].apply(lambda x: 0 if 'promotional' in str(x).lower() else 1)\n    df = df.rename(columns = {'rule 4':'Promotions allowed'})\n    ##column 1: advertising\n    df['rule 3'] = df['rule 3'].apply(lambda x: 0 if 'advertising' in str(x).lower() else 1)\n    df = df.rename(columns = {'rule 3':'Advertising allowed'})\n    ## Dealing with  spam part using new created dataframe\n    df_1 = df['rule 1'].str.split(':',expand=True)\n    df = df.drop(columns = ['rule 1'])\n\n    df_1.columns = ['Advert','spam']\n    df_1 = df_1.drop(columns = ['Advert'])\n    \n    df_1['spam allowed'] = df_1['spam'].apply(lambda x: 0 if 'spam' in str(x).lower() else 1)\n    df['spam allowed'] = df_1['spam allowed']\n    ## Double checked with  original dataframe, works fine till here.\n\n    for i in df.columns:\n        dataframe[i] = df[i]\n\n    ##making this part custom since testing part doesn't have rule_violation part\n        \n    df_original = dataframe[['body', 'rule_violation','referral link allowed', 'Advertising allowed',\n           'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n    \n    df_p1 = dataframe[['positive_example_1','rule_violation','referral link allowed', 'Advertising allowed',\n               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n    df_p1.loc[:,'rule_violation'] = 0\n    df_p1 = df_p1.rename(columns = {'positive_example_1':'body'})\n        \n    df_p2 = dataframe[['positive_example_2','rule_violation','referral link allowed', 'Advertising allowed',\n               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n    df_p2.loc[:,'rule_violation'] = 0\n    df_p2 = df_p2.rename(columns = {'positive_example_2':'body'})\n        \n    df_n1 = dataframe[['negative_example_1','rule_violation','referral link allowed', 'Advertising allowed',\n               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n    df_n1.loc[:,'rule_violation'] = 1\n    df_n1 = df_n1.rename(columns = {'negative_example_1':'body'})\n        \n    df_n2 = dataframe[['negative_example_2','rule_violation','referral link allowed', 'Advertising allowed',\n               'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]\n    df_n2.loc[:,'rule_violation'] = 1\n    df_n2 = df_n2.rename(columns = {'negative_example_2':'body'})\n    \n    df_total = pd.concat([df_original,df_p1,df_p2,df_n1,df_n2], axis = 0,ignore_index=True)\n\n    text_file = df_total['body'].to_list()\n    \n    pattern = re.compile('https?:\\/\\/\\S+|www\\.\\S+|Https?:\\/\\/\\S+|\\S+\\.com\\S+|\\S+\\.com|\\[.*?\\]|\\S+ \\. com.*')   ## Removing URLs\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n    \n    pattern = re.compile('<.*?>')       ##Removing HTML rags\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i]) \n    \n    pattern = re.compile('#\\S+|@\\S+|\\S+\\@\\S+|\\S+@')             ## Removing Emails and Hashtags\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])            ### Removing username and subreddit mentions\n    \n    pattern = re.compile('u\\/\\S+|r\\/\\S+')\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n        \n    pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n\n    pattern = re.compile('\\d|\\\\n')             ##Removing Numbers & \\n spaces\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n\n\n    ## Works perfectly\n\n    x = df_total.drop(columns = ['rule_violation'])\n    y = df_total['rule_violation']\n\n    x = x.drop(columns = ['body'])\n    \n    lemmatizer = WordNetLemmatizer()\n\n    cleaned_text = []\n    preprocessed_training_text = []\n    for i in range(len(x)):\n        text1 = re.sub('[^a-zA-Z]',' ',text_file[i])\n        text1 = text1.lower()\n        text1 = [lemmatizer.lemmatize(word) for word in text1 if word not in combined_stopwords]\n        cleaned_text = ''.join(text1)\n        preprocessed_training_text.append(cleaned_text)\n    \n\n    return x,y,preprocessed_training_text\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:46:17.321232Z","iopub.execute_input":"2025-08-03T06:46:17.321528Z","iopub.status.idle":"2025-08-03T06:46:17.337676Z","shell.execute_reply.started":"2025-08-03T06:46:17.321504Z","shell.execute_reply":"2025-08-03T06:46:17.336833Z"}},"outputs":[],"execution_count":150},{"cell_type":"code","source":"def testing_data_prep(dataframe):\n    df = dataframe['rule'].str.split(',',expand=True)\n    df.fillna('0',inplace=True)\n    df.columns = ['rule 1','rule 2','rule 3','rule 4']\n    ## till here it works perfectly\n    df['rule 2'] = df['rule 2'].apply(lambda x : 1 if 'referral links' in str(x).lower() else 0)\n    df = df.rename(columns = {'rule 2':'referral link allowed'})\n    #column 0 (legal_advice)\n    df['legal_advice_allowed'] = df['rule 1'].apply(lambda x: 0 if 'legal' in str(x).lower() else 1)\n    #column 1\n    df['rule 4'] = df['rule 4'].apply(lambda x: 0 if 'promotional' in str(x).lower() else 1)\n    df = df.rename(columns = {'rule 4':'Promotions allowed'})\n    ##column 1: advertising\n    df['rule 3'] = df['rule 3'].apply(lambda x: 0 if 'advertising' in str(x).lower() else 1)\n    df = df.rename(columns = {'rule 3':'Advertising allowed'})\n    ## Dealing with  spam part using new created dataframe\n    df_1 = df['rule 1'].str.split(':',expand=True)\n    df = df.drop(columns = ['rule 1'])\n\n    df_1.columns = ['Advert','spam']\n    df_1 = df_1.drop(columns = ['Advert'])\n    \n    df_1['spam allowed'] = df_1['spam'].apply(lambda x: 0 if 'spam' in str(x).lower() else 1)\n    df['spam allowed'] = df_1['spam allowed']\n    ## Double checked with  original dataframe, works fine till here.\n\n    for i in df.columns:\n        dataframe[i] = df[i]\n    \n    df_total = dataframe[['body','referral link allowed', 'Advertising allowed',\n           'Promotions allowed', 'legal_advice_allowed', 'spam allowed']]        \n\n    ## Till here, everything works fine as well, tested properly.\n    \n    text_file = df_total['body'].to_list()\n    \n    pattern = re.compile('https?:\\/\\/\\S+|www\\.\\S+|Https?:\\/\\/\\S+|\\S+\\.com\\S+|\\S+\\.com|\\[.*?\\]|\\S+ \\. com.*')   ## Removing URLs\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n    \n    pattern = re.compile('<.*?>')       ##Removing HTML rags\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i]) \n    \n    pattern = re.compile('#\\S+|@\\S+|\\S+\\@\\S+|\\S+@')             ## Removing Emails and Hashtags\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])            ### Removing username and subreddit mentions\n    \n    pattern = re.compile('u\\/\\S+|r\\/\\S+')\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n        \n    pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n\n    pattern = re.compile('\\d|\\\\n')             ##Removing Numbers & \\n spaces\n    for i in range(len(text_file)):\n        text_file[i] = pattern.sub(r'',text_file[i])\n\n    lemmatizer = WordNetLemmatizer()\n\n    cleaned_text = []\n    preprocessed_testing_text = []\n    for i in range(len(df_total)):\n        text1 = re.sub('[^a-zA-Z]',' ',text_file[i])\n        text1 = text1.lower()\n        text1 = [lemmatizer.lemmatize(word) for word in text1 if word not in combined_stopwords]\n        cleaned_text = ''.join(text1)\n        preprocessed_testing_text.append(cleaned_text)\n    \n    ##Works perfectly fine till now.\n\n    df_total = df_total.drop(columns = ['body'])\n    \n    return df_total,preprocessed_testing_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:46:31.127690Z","iopub.execute_input":"2025-08-03T06:46:31.128366Z","iopub.status.idle":"2025-08-03T06:46:31.143712Z","shell.execute_reply.started":"2025-08-03T06:46:31.128339Z","shell.execute_reply":"2025-08-03T06:46:31.142884Z"}},"outputs":[],"execution_count":151},{"cell_type":"code","source":"x_features,y_target, preprocessed_training_text = training_data_prep(df_train)\nx_test,preprocessed_testing_text = testing_data_prep(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:46:33.035584Z","iopub.execute_input":"2025-08-03T06:46:33.035921Z","iopub.status.idle":"2025-08-03T06:46:36.689201Z","shell.execute_reply.started":"2025-08-03T06:46:33.035881Z","shell.execute_reply":"2025-08-03T06:46:36.688294Z"}},"outputs":[],"execution_count":152},{"cell_type":"code","source":"token = Tokenizer(num_words = 5000, oov_token='<OOV>')\n##training text tokenization and padding\n\ntoken.fit_on_texts(preprocessed_training_text)\nmax_length = max(len(i.split()) for i in preprocessed_training_text)\ntraining_sequence = token.texts_to_sequences(preprocessed_training_text)\nx_train = pad_sequences(training_sequence, maxlen=max_length, padding='post')\n    \n    ##Testing Text tokenization and padding\n    \ntesting_sequence = token.texts_to_sequences(preprocessed_testing_text)\nx_test = pad_sequences(testing_sequence, maxlen=max_length, padding='post')\n\n    # TENSORFLOW ARCHITECTURE HERE\n    ## Feature dataset input preprocessing\nfeature_input = Input(shape=(5,), name = 'other_feature')\ny = Dense(64, activation='relu')(feature_input)\ny = BatchNormalization()(y)\ny = Dropout(0.3)(y)\ny = Dense(64, activation='relu')(y)\n    \n    ## Text input preprocessing\ntext_input = Input(shape=(83,), name='text_input')\nembedding = Embedding(input_dim = 5000, output_dim = 128)(text_input)\nx1 = Bidirectional(LSTM(128, return_sequences=True))(embedding)\n    \n    # Multi-Head Attention for better context\nx2 = MultiHeadAttention(num_heads=4, key_dim=64)(x1, x1)\n    \n    # Combine Attention output with LSTM via Residual Connection\nx2 = Add()([x1, x2])  # residual connection\n    \n    # Pooling to flatten sequence\nx = GlobalAveragePooling1D()(x2)\n    \n    \ncombined = Concatenate()([x,y])\nrnn1 = Dense(128, activation='relu')(combined)\nrnn2 = Dense(64, activation='relu')(rnn1)\ndense3 = Dense(32, activation='relu')(rnn2)\noutput = Dense(1, activation='sigmoid')(dense3)\n    \nmodel = Model(inputs=[text_input, feature_input], outputs=output)\nadam = Adam(learning_rate = 0.001)\nmodel.compile(optimizer=adam, loss='binary_crossentropy', metrics=[AUC(curve='ROC', name='roc_auc')])  \n\nhistory = model.fit(\n    {'text_input': x_train, 'other_feature': x_features},\n    y_target,\n    epochs=25, batch_size=64, verbose = 1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:46:40.055626Z","iopub.execute_input":"2025-08-03T06:46:40.055921Z","iopub.status.idle":"2025-08-03T06:46:40.558837Z","shell.execute_reply.started":"2025-08-03T06:46:40.055899Z","shell.execute_reply":"2025-08-03T06:46:40.557927Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T06:46:45.091140Z","iopub.execute_input":"2025-08-03T06:46:45.091412Z","iopub.status.idle":"2025-08-03T06:47:05.832603Z","shell.execute_reply.started":"2025-08-03T06:46:45.091393Z","shell.execute_reply":"2025-08-03T06:47:05.831176Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n\u001b[1m 31/159\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 318ms/step - loss: 0.6945 - roc_auc: 0.5308","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/513539064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'text_input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'other_feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":156},{"cell_type":"code","source":"y_pred = model.predict({'text_input': x_test, 'other_feature': preprocessed_testing_text})\nfrom sklearn.metrics import roc_auc_score\n#roc_auc_test = roc_auc_score(y_test, y_pred)\n#print(f\"Test ROC-AUC: {roc_auc_test:.4f}\")\n\nprint(y_pred)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}